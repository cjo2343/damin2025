{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04874d38",
   "metadata": {},
   "source": [
    "# Loading CSV Files with Pandas\n",
    "\n",
    "This notebook demonstrates how to use the Pandas library to load and explore CSV files. CSV (Comma-Separated Values) files are one of the most common data formats for storing structured data.\n",
    "\n",
    "## Learning Objectives\n",
    "- Import the Pandas library\n",
    "- Load CSV files into DataFrames\n",
    "- Understand DataFrame structure and properties\n",
    "- Preview data with head() and tail() methods\n",
    "- Inspect data types and missing values\n",
    "- Handle common data loading scenarios\n",
    "\n",
    "## Prerequisites\n",
    "- Basic understanding of Python\n",
    "- Pandas library installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ce8c8",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "First, we need to import the Pandas library, which provides powerful data manipulation and analysis tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52447af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas library imported successfully!\n",
      "Pandas version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Pandas library imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1fe56",
   "metadata": {},
   "source": [
    "## Step 2: Load CSV File into DataFrame\n",
    "\n",
    "A DataFrame is Pandas' primary data structure for storing and manipulating tabular data. We'll load our CSV file into a DataFrame for analysis.\n",
    "\n",
    "**Note:** Make sure the CSV file exists at the specified path. You may need to adjust the file path according to your directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ba9f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load the CSV file into a DataFrame\n",
    "# Replace './data/data.csv' with the path to your actual CSV file\n",
    "try:\n",
    "    df = pd.read_csv(\"./data/data.csv\")\n",
    "    print(\"CSV file loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"CSV file not found. Please check the file path.\")\n",
    "    # Create a sample DataFrame for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "        'Age': [25, 30, 35, 28, 32],\n",
    "        'City': ['New York', 'London', 'Tokyo', 'Paris', 'Sydney'],\n",
    "        'Salary': [50000, 60000, 55000, 48000, 62000]\n",
    "    })\n",
    "    print(\"Using sample data instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c294c1",
   "metadata": {},
   "source": [
    "## Step 3: Understanding DataFrame Shape\n",
    "\n",
    "The shape of a DataFrame tells us the number of rows and columns in our dataset. This is crucial for understanding the size of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c96590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (1000, 4)\n",
      "Number of rows: 1000\n",
      "Number of columns: 4\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Understanding the shape of your DataFrame\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9538d",
   "metadata": {},
   "source": [
    "## Step 4: Preview the Data\n",
    "\n",
    "Previewing the data helps us understand what our dataset looks like without loading all the data at once. This is especially useful for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16dd9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the first 5 rows of the DataFrame:\n",
      "    Name   Age       City Grade\n",
      "0   Sara  50.0  San Diego     F\n",
      "1   Emma  57.0  San Diego     C\n",
      "2  David  29.0   New York     D\n",
      "3  Chris  53.0   San Jose     D\n",
      "4   Sara  21.0    Phoenix     A\n",
      "\n",
      "Preview of the last 10 rows of the DataFrame:\n",
      "      Name   Age         City Grade\n",
      "990  David  38.0  San Antonio     C\n",
      "991   Mike  39.0     New York     F\n",
      "992   Mike  45.0      Houston     A\n",
      "993  David  26.0  Los Angeles   NaN\n",
      "994   Sara  43.0  Los Angeles     D\n",
      "995  James  26.0  Los Angeles     F\n",
      "996  James   NaN      Houston     C\n",
      "997  David  27.0     New York   NaN\n",
      "998  Alice  41.0      Houston     C\n",
      "999  Laura  59.0  Los Angeles     B\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Preview the first and last few rows of the DataFrame\n",
    "print(\"Preview of the first 5 rows of the DataFrame:\")\n",
    "print(df.head())  # Displays the first 5 rows\n",
    "\n",
    "print(\"\\nPreview of the last 10 rows of the DataFrame:\")\n",
    "print(df.tail(10))  # Displays the last 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befa0d1",
   "metadata": {},
   "source": [
    "## Step 5: Inspect DataFrame Structure\n",
    "\n",
    "The `info()` method provides a comprehensive overview of the DataFrame, including column names, data types, non-null counts, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021d79ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame structure and data types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Name    1000 non-null   object \n",
      " 1   Age     996 non-null    float64\n",
      " 2   City    994 non-null    object \n",
      " 3   Grade   992 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Inspect the structure of the DataFrame\n",
    "print(\"DataFrame structure and data types:\")\n",
    "print(df.info())  # Provides a summary of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a7cdf",
   "metadata": {},
   "source": [
    "## Step 6: Handle Missing Values\n",
    "\n",
    "Missing values are common in real-world datasets. Identifying and handling them is crucial for data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47ed532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values:\n",
      "Name     0\n",
      "Age      4\n",
      "City     6\n",
      "Grade    8\n",
      "dtype: int64\n",
      "\n",
      "Percentage of missing values:\n",
      "Name     0.0\n",
      "Age      0.4\n",
      "City     0.6\n",
      "Grade    0.8\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Optional: Handling common issues\n",
    "# Handling missing values: Checking for NaN values\n",
    "print(\"Checking for missing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)  # Displays the number of missing values per column\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e359d",
   "metadata": {},
   "source": [
    "## Advanced Loading Techniques\n",
    "\n",
    "Here are some additional techniques for loading CSV files in different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2572abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced loading techniques are commented out.\n",
      "Uncomment the lines above to try different loading scenarios.\n"
     ]
    }
   ],
   "source": [
    "# Advanced loading techniques (commented out - uncomment to try)\n",
    "\n",
    "# 1. Loading only a portion of a large file (e.g., first 100 rows)\n",
    "# df_sample = pd.read_csv(\"lecture02/data/data.csv\", nrows=100)\n",
    "# print(f\"Sample DataFrame shape: {df_sample.shape}\")\n",
    "\n",
    "# 2. Loading with custom column names\n",
    "# custom_columns = ['col1', 'col2', 'col3', 'col4']\n",
    "# df_custom = pd.read_csv(\"lecture02/data/data.csv\", names=custom_columns)\n",
    "\n",
    "# 3. Loading with specific data types\n",
    "# dtype_dict = {'column_name': 'str', 'numeric_column': 'float64'}\n",
    "# df_typed = pd.read_csv(\"lecture02/data/data.csv\", dtype=dtype_dict)\n",
    "\n",
    "# 4. Loading from different directory\n",
    "# df_remote = pd.read_csv(\"/path/to/your/data.csv\")\n",
    "\n",
    "# 5. Loading with different separators\n",
    "# df_semicolon = pd.read_csv(\"data.csv\", sep=';')\n",
    "\n",
    "print(\"Advanced loading techniques are commented out.\")\n",
    "print(\"Uncomment the lines above to try different loading scenarios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84d8eb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "\n",
    "1. **Import Pandas**: Essential library for data manipulation\n",
    "2. **Load CSV files**: Using `pd.read_csv()` function\n",
    "3. **Understand data shape**: Number of rows and columns\n",
    "4. **Preview data**: Using `head()` and `tail()` methods\n",
    "5. **Inspect structure**: Using `info()` method for comprehensive overview\n",
    "6. **Check for missing values**: Using `isnull().sum()` to identify data quality issues\n",
    "7. **Advanced loading techniques**: Various parameters for different scenarios\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "- Always check the file path before loading\n",
    "- Preview your data to understand its structure\n",
    "- Check for missing values and handle them appropriately\n",
    "- Use `nrows` parameter for large files to load samples first\n",
    "- Specify data types when needed for better performance\n",
    "- Handle file loading errors gracefully\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Learn about data cleaning and preprocessing\n",
    "- Explore data visualization with Pandas and Matplotlib\n",
    "- Practice with different CSV files and formats\n",
    "- Learn about other data formats (Excel, JSON, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "damin2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
